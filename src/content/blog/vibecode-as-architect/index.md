---
title: "Vibecode as an Architect: Don't Vibe-Architect"
publishDate: 2025-05-30 00:00:00
img: "./image.png"
img_alt: Vibecode and Vibedebug.
description: |
  AI is changing how we build softwareâ€”but not always how youâ€™d expect. As an architect, I thought LLMs would help me code less. Instead, they pulled me deeper into the trenches. In this post, I share what it's like to build with AI at your side, the traps non-engineers fall into, and why prototyping is just the beginning.
tags:
  - Architecture
  - Software Development
  - AI Tools
  - Vibecoding
  - LLM
---

AI-assisted coding is hereâ€”like it or not. As large language models (LLMs) get better at writing and debugging code, weâ€™re learning how to work alongside them. But contrary to what you might think, they donâ€™t always mean *less* coding. In my case, itâ€™s been the opposite.

Over the past few years, working as a software architect, Iâ€™ve been deeper in code than everâ€”reviewing, refining, and debugging LLM-generated output. The landscape is changing fast, and staying on top means getting your hands dirty.

Iâ€™ve seen people from marketing, finance, and other domains jump into coding with the help of AI. They get excited, build little tools, learn some Pythonâ€”and sometimes even ship something useful. But that doesnâ€™t make them software engineers, and theyâ€™re certainly not deploying systems at scale. Owning a gun and knowing how to shoot doesnâ€™t make you a soldier.

LLMs let you build fast. You can bootstrap a prototype with minimal experience. But once the project grows beyond a handful of files, you're deep in vibe-debugging landâ€”chasing hallucinations, losing context, and untangling obscure logic.

The tooling is improvingâ€”copilots, agents, longer context. But the farther you go without discipline, the more likely youâ€™ll get stuck. This post isnâ€™t about dismissing AI coding. Itâ€™s about building responsibly with LLMsâ€”especially when you're leading the architecture.

Here are the principles that keep me sane while building with AI.

---

## ğŸ§¾ Start With Project Context

Before writing code, write a simple product brief. Save it as `README.md`, `project.md`, or `context.md`.

Include:

1. **Users and roles**
2. **Main use cases**
3. **Key integrations** (and their limits)
4. **Constraints** (budget, deadlines, infrastructure, etc.)

This doc isn't a spec. Itâ€™s a north starâ€”reminding you (and your LLM) what problem you're solving.

---

## ğŸ¨ Sketch Before You Paint

LLMs tend to overbuild. You'll get layers of exception handling, edge cases, and opinionated patternsâ€”before you've even validated the basics.

Instead, start like an artist: create a rough sketch. Focus on structure, not polish. Ask your LLM for skeletons, not final drafts. Youâ€™ll move faster and stay in control.

---

## ğŸ› ï¸ Use the Stack You Know

Vibecoding isn't just codingâ€”it's mostly debugging. And when your LLM hits a wall, **you** have to step in.

Stick with stacks you know well. That cool new Rust framework might look fun, but if you're fluent in PHP or Django, youâ€™ll save hours of review and rewrites.

Familiar tech also improves maintainability. LLMs and teammates are both more likely to understand Django than that hip new meta-framework.

---

## ğŸ§± Monolith First

![Gru's plan on microservices](./grus-plan-microservices.png)

Unless you're a Kubernetes expert, avoid microservices early on.

Start with a monolith. Keep it modular. You can always extract services later. Most modern frameworks support clean separation and will scale farther than you think.

Premature scaling kills momentum. Solve real problems, not hypothetical ones.

---

## ğŸ” Stay in Control

Letâ€™s be honestâ€”code review isnâ€™t fun. But LLM-driven development turns your entire process into one long code review.

Read everything. Donâ€™t blindly trust completions. LLMs hallucinate. They forget context. They make confident mistakes.

Break work into chunks. Review as you go. Commit when things are stable. Repeat.

---

## ğŸ’¾ Commit With Discipline

![Git history for archeologists](./git.png)

- Make atomic commits
- Write concise, helpful messages
- Donâ€™t hoard changesâ€”or spam commits
- Avoid messy branching unless necessary

Assume anything you're working on could be thrown away tomorrow. Keep your history clean.

---

## ğŸš€ Deploy Day One
![Surprise...](./aws-lambda-meme.png)

Get something live on day one. Even a simple â€œHello Worldâ€ forces you to validate assumptions about infrastructure, runtime, and stack choices.

Avoid jumping into serverless too early. Vercel, Lambda, and similar platforms are convenientâ€”but they can be costly traps if misused. Iâ€™ve seen projects rack up five-figure bills after a viral spike.

Instead, default to:

- **Docker**
- **Open-source database**
- **Simple VM or container host**

This setup gives you freedom to scale, migrate, or bail when needed.

---

## ğŸ§  Conclusion

![Vibecoding is fine](./fine-dog-vibecode.png)

Vibecoding is powerfulâ€”but only if you stay in the driver's seat. AI wonâ€™t replace engineers who understand systems, constraints, and users. But it *will* supercharge the ones who do.

As architects, we donâ€™t just write code. We set direction, manage trade-offs, and take responsibility. LLMs donâ€™t take that awayâ€”they make it even more important.

Use the tools. But donâ€™t vibe your architecture into chaos.

---

## ğŸ“ Bonus: PRD Template

```
# Vibecode â€“ Product Requirements Document (PRD)

**Author:** Oleksiy Zelenyuk  
**Date:** 2025-05-30  
**Version:** 0.1  
**Status:** Draft

---

## ğŸ§­ Purpose

Vibecode is a lightweight AI-assisted coding workflow tailored for software architects and senior engineers. It helps prototype and deliver clean, maintainable systems using LLMs, without losing control over architecture, tech stack, and deployments.

---

## ğŸ‘¥ Target Users

- **Software Architects** â€“ care about design and maintainability  
- **Senior Developers** â€“ use AI but want more structure  
- **Tech Leads / CTOs** â€“ need consistency in AI workflows  
- **AI-curious non-devs** â€“ experimenters needing guardrails

---

## ğŸ§© Key Features

- **Project Context Generator** â€“ roles, goals, constraints in Markdown  
- **Sketch-First Prompts** â€“ focus on structure before logic  
- **Stack Guardrails** â€“ stick to familiar, maintainable tech  
- **Monolith-First Templates** â€“ MVP-friendly, modular-ready codebases  
- **Commit Coach** â€“ guides atomic, well-labeled Git commits  
- **Deployment Bootstrap** â€“ Docker + open DB, serverless warnings

---

## ğŸ§ª Success Metrics

- â± MVP in < 2 hours  
- ğŸ” 60%+ returning users in 30 days  
- ğŸª² 75%+ bugs caught during review  
- ğŸ§± 90%+ complete MVP in original stack

---

## ğŸ“¦ Requirements

**Functional:**  
- Context markdown  
- Prompt templates  
- Git & LLM integration  
- Docker deploy script

**Non-Functional:**  
- CLI or lightweight UI  
- Offline/local LLM support  
- Minimal telemetry (opt-in)

---

## ğŸš§ Risks & Constraints

| Risk                         | Mitigation                         |
|-----------------------------|-------------------------------------|
| LLM hallucinations           | Review-first workflow               |
| Stack misuse                 | Strong defaults + warnings          |
| Lock-in to serverless        | Docker-first deploy strategy        |

---

## ğŸ“… Timeline

- âœ… **May** â€“ Concept & blog post  
- ğŸ”¨ **Junâ€“Jul** â€“ MVP build  
- ğŸ§ª **Aug** â€“ Alpha testing  
- ğŸš€ **Sep** â€“ Public beta

---

## â“Open Questions

- CLI, VS Code extension, or Web UI?  
- Which LLMs to support (OpenAI, local)?  
- Community stack templates?  
```
